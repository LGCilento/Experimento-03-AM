{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "one-class-classification-algorithms-kc1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWrUFd4s8OX7O/h9kUyfD8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LGCilento/Experimento-03-AM/blob/master/one_class_classification_algorithms_kc1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUEMTCuiZxQ8"
      },
      "source": [
        "<h1><b>One-class-classification-algorithms</b></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrjqa0xBZxRO"
      },
      "source": [
        "<h2>Data-Preparation</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1XMv__DZxRP"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "from math import floor\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnTyyFOMZxRP",
        "outputId": "b2e5b324-be22-40b2-a33d-12deab8564a1"
      },
      "source": [
        "data = arff.loadarff(\"kc1.arff\")\n",
        "df = pd.DataFrame(data[0])\n",
        "df.rename(columns = {'defects': 'problems'}, inplace = True)\n",
        "df['problems'] = df['problems'].apply(lambda x: x.decode(\"utf-8\"))\n",
        "df['problems'] = df['problems'].map({\"false\": 0, \"true\": 1})\n",
        "df['problems']"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "2104    0\n",
              "2105    0\n",
              "2106    0\n",
              "2107    0\n",
              "2108    0\n",
              "Name: problems, Length: 2109, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJaEiMlqXd5c"
      },
      "source": [
        "def split_db_pos_neg(df):\n",
        "  df = shuffle(df)\n",
        "  negative_database = df.loc[df['problems'] <= 0]\n",
        "  positive_database = df.loc[df['problems'] > 0]\n",
        "  return negative_database,positive_database"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhuXIw0Z8pUt"
      },
      "source": [
        "train Base at 30%:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHAS5FaCoBZP"
      },
      "source": [
        "def train_test_30(negative_database,positive_database,train_array_size):\n",
        "  train_30 = negative_database[0:train_array_sizes[0]]\n",
        "  test_30 = pd.concat([negative_database[train_array_sizes[0]:],positive_database])\n",
        "  train_y_30 = train_30['problems'].values\n",
        "  train_x_30 = train_30.drop(columns=['problems']).values\n",
        "  test_y_30 = test_30['problems'].values\n",
        "  test_x_30 = test_30.drop(columns=['problems']).values\n",
        "  return train_x_30,test_x_30,test_y_30"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7K3jlUx9EnI"
      },
      "source": [
        "train Base at 40%:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-WSUjHA9dL2"
      },
      "source": [
        "def train_test_40(negative_database,positive_database,train_array_size):\n",
        "  train_40 = negative_database[0:train_array_sizes[1]]\n",
        "  test_40 = pd.concat([negative_database[train_array_sizes[1]:],positive_database])\n",
        "  train_y_40 = train_40['problems'].values\n",
        "  train_x_40 = train_40.drop(columns=['problems']).values\n",
        "  test_y_40 = test_40['problems'].values\n",
        "  test_x_40 = test_40.drop(columns=['problems']).values\n",
        "  return train_x_40,test_x_40,test_y_40"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI8jSO8H9gx_"
      },
      "source": [
        "train Base at 50%:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qNC40AZ9wun"
      },
      "source": [
        "def train_test_50(negative_database,positive_database,train_array_size):\n",
        "  train_50 = negative_database[0:train_array_sizes[2]]\n",
        "  test_50 = pd.concat([negative_database[train_array_sizes[2]:],positive_database])\n",
        "  train_y_50 = train_50['problems'].values\n",
        "  train_x_50 = train_50.drop(columns=['problems']).values\n",
        "  test_y_50 = test_50['problems'].values\n",
        "  test_x_50 = test_50.drop(columns=['problems']).values\n",
        "  return train_x_50,test_x_50,test_y_50"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VE60xEu93Om"
      },
      "source": [
        "<h2><b>One-class-classification Algorithms</b></h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRoNw4cAUTrm"
      },
      "source": [
        "def execute_benchmark(model,negative_database,positive_database,train_array_sizes):   ## Função para benchmark dos modelos\n",
        "  f1_score_list_30 = []\n",
        "  f1_score_list_40 = []\n",
        "  f1_score_list_50 = []\n",
        "  for exec in range(0,100):\n",
        "    train_x_30,test_x_30,test_y_30 = train_test_30(negative_database,positive_database,train_array_sizes)\n",
        "    train_x_40,test_x_40,test_y_40 = train_test_40(negative_database,positive_database,train_array_sizes)\n",
        "    train_x_50,test_x_50,test_y_50 = train_test_40(negative_database,positive_database,train_array_sizes)\n",
        "    train_test_list = [(train_x_30,test_x_30,test_y_30,'30'),(train_x_40,test_x_40,test_y_40,'40'),(train_x_50,test_x_50,test_y_50,'50')]\n",
        "    for i in train_test_list:\n",
        "      train_x, test_x, test_y, label = i\n",
        "      model.fit(train_x)\n",
        "      yhat = model.predict(test_x)\n",
        "      test_y[test_y == 1] = -1\n",
        "      test_y[test_y == 0] = 1\n",
        "      score = f1_score(test_y,yhat,pos_label=-1)\n",
        "      #print('F1 Score for {}: {}'.format(label,score))\n",
        "      if label == '30':\n",
        "        f1_score_list_30.append(score)\n",
        "      elif label == '40':\n",
        "        f1_score_list_40.append(score)\n",
        "      else:\n",
        "        f1_score_list_50.append(score)\n",
        "  print(\"F1-Score 30%: {} (+/- {})\".format(np.mean(f1_score_list_30),np.std(f1_score_list_30)))\n",
        "  print(\"F1-Score 40%: {} (+/- {})\".format(np.mean(f1_score_list_40),np.std(f1_score_list_40)))\n",
        "  print(\"F1-Score 50%: {} (+/- {})\".format(np.mean(f1_score_list_50),np.std(f1_score_list_50)))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT5H0AUk-F4a"
      },
      "source": [
        "<h3><b>Minimum Covariance Determinant:</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CJtIOrct398",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5769de6f-5925-448c-c566-ddf42ed80a8f"
      },
      "source": [
        "from sklearn.covariance import EllipticEnvelope\n",
        "model_mcd = EllipticEnvelope(contamination=0.20)\n",
        "negative_database,positive_database = split_db_pos_neg(df)\n",
        "train_array_sizes = [floor(negative_database.shape[0]*0.3),floor(negative_database.shape[0]*0.4),floor(negative_database.shape[0]*0.5)]\n",
        "execute_benchmark(model_mcd,negative_database,positive_database,train_array_sizes)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score 30%: 0.5289128837056051 (+/- 0.004068250254933467)\n",
            "F1-Score 40%: 0.5560929370398565 (+/- 0.005996061545261575)\n",
            "F1-Score 50%: 0.5556942054584639 (+/- 0.006131339026842997)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnpVb8HUIpZ8"
      },
      "source": [
        "<h3><b>Local Outlier Factor:</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF4zJybXI6n1"
      },
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from numpy import vstack\n",
        "model_lof = LocalOutlierFactor(contamination=0.20)\n",
        "negative_database,positive_database = split_db_pos_neg(df)\n",
        "train_array_sizes = [floor(negative_database.shape[0]*0.3),floor(negative_database.shape[0]*0.4),floor(negative_database.shape[0]*0.5)]\n",
        "#execute_benchmark(model_lof)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6vCYOcLIxDX",
        "outputId": "306f82a6-6c7a-4d27-d5a2-a3e1e80e836a"
      },
      "source": [
        "f1_score_list_30 = []  # função de benchmark adaptada para Local Outlier Factor\n",
        "f1_score_list_40 = []\n",
        "f1_score_list_50 = []\n",
        "for exec in range(0,100):\n",
        "  train_x_30,test_x_30,test_y_30 = train_test_30(negative_database,positive_database,train_array_sizes)\n",
        "  train_x_40,test_x_40,test_y_40 = train_test_40(negative_database,positive_database,train_array_sizes)\n",
        "  train_x_50,test_x_50,test_y_50 = train_test_40(negative_database,positive_database,train_array_sizes)\n",
        "  train_test_list = [(train_x_30,test_x_30,test_y_30,'30'),(train_x_40,test_x_40,test_y_40,'40'),(train_x_50,test_x_50,test_y_50,'50')]\n",
        "  for i in train_test_list:\n",
        "    train_x, test_x, test_y,label = i\n",
        "    composite = vstack((train_x, test_x))\n",
        "    yhat = model_lof.fit_predict(composite)\n",
        "    # get just the predictions on the test set\n",
        "    yhat = yhat[len(train_x):]\n",
        "\n",
        "    test_y[test_y == 1] = -1\n",
        "    test_y[test_y == 0] = 1\n",
        "    score = f1_score(test_y,yhat,pos_label=-1)\n",
        "    if label == '30':\n",
        "      f1_score_list_30.append(score)\n",
        "    elif label == '40':\n",
        "      f1_score_list_40.append(score)\n",
        "    else:\n",
        "      f1_score_list_50.append(score)\n",
        "print(\"F1-Score 30%: {} (+/- {})\".format(np.mean(f1_score_list_30),np.std(f1_score_list_30)))\n",
        "print(\"F1-Score 40%: {} (+/- {})\".format(np.mean(f1_score_list_40),np.std(f1_score_list_40)))\n",
        "print(\"F1-Score 50%: {} (+/- {})\".format(np.mean(f1_score_list_50),np.std(f1_score_list_50)))\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score 30%: 0.25116279069767433 (+/- 1.1102230246251565e-16)\n",
            "F1-Score 40%: 0.2647058823529412 (+/- 0.0)\n",
            "F1-Score 50%: 0.2647058823529412 (+/- 0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnMjcYisKgi2"
      },
      "source": [
        "<h3><b>Isolation Forest:</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UvEgrvtLnj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b389021-3190-42e5-ec48-54800e501b41"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "model_IF = IsolationForest(contamination=0.20)\n",
        "negative_database,positive_database = split_db_pos_neg(df)\n",
        "train_array_sizes = [floor(negative_database.shape[0]*0.3),floor(negative_database.shape[0]*0.4),floor(negative_database.shape[0]*0.5)]\n",
        "execute_benchmark(model_IF,negative_database,positive_database,train_array_sizes)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score 30%: 0.5209731311808957 (+/- 0.006398416435551614)\n",
            "F1-Score 40%: 0.5410833892369045 (+/- 0.005849625454789325)\n",
            "F1-Score 50%: 0.540647177828821 (+/- 0.006507774868150787)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxIMiwajMQB6"
      },
      "source": [
        "<h3><b>One-Class Support Vector Machines:</b></h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_C8Gk2JMb7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e227e2d-defd-438f-b099-e8c2951c0edb"
      },
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "model_OCSVM = OneClassSVM(gamma='scale', nu=0.20)\n",
        "negative_database,positive_database = split_db_pos_neg(df)\n",
        "train_array_sizes = [floor(negative_database.shape[0]*0.3),floor(negative_database.shape[0]*0.4),floor(negative_database.shape[0]*0.5)]\n",
        "execute_benchmark(model_OCSVM,negative_database,positive_database,train_array_sizes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-Score 30%: 0.35260930888575454 (+/- 5.551115123125783e-17)\n",
            "F1-Score 40%: 0.39941262848751835 (+/- 0.0)\n",
            "F1-Score 50%: 0.39941262848751835 (+/- 0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}